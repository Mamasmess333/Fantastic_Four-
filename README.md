# ğŸ§  BiteWise AI - Food Image Analysis Platform

A full-stack **BiteWise AI** application that uses **AWS Rekognition**, **S3**, and **PostgreSQL** to identify food items from uploaded images and store analysis results. Built with **FastAPI** backend and vanilla JavaScript frontend.

---

## ğŸš€ Features

- **Image Upload & Analysis**: Upload food images and analyze them using AWS Rekognition
- **Cloud Storage**: Automatic upload to Amazon S3 with unique file identifiers
- **Database Persistence**: Store analysis results in PostgreSQL (AWS RDS)
- **RESTful API**: Fully integrated FastAPI backend with organized routes and services
- **Static Frontend Hosting**: Serves HTML/CSS/JS frontend directly from FastAPI
- **CORS-enabled**: Ready for frontend integration
- **Secure Configuration**: Environment-based setup for AWS and database credentials

---

## ğŸ§© Project Structure

```
Fantastic_Four-/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                    # FastAPI main entry point
â”‚   â”œâ”€â”€ init_db.py                # Database initialization script
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                   # API route handlers
â”‚   â”‚   â”œâ”€â”€ upload.py             # Image upload & analysis endpoint
â”‚   â”‚   â””â”€â”€ analysis.py           # Additional analysis endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                 # Business logic services
â”‚   â”‚   â”œâ”€â”€ ai_service.py         # AWS Rekognition integration
â”‚   â”‚   â”œâ”€â”€ s3_service.py         # S3 file upload service
â”‚   â”‚   â””â”€â”€ db_service.py         # Database operations
â”‚   â”‚
â”‚   â”œâ”€â”€ database/                 # Database configuration
â”‚   â”‚   â””â”€â”€ connection.py         # SQLAlchemy engine & session
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                   # Database models
â”‚   â”‚   â””â”€â”€ analysis_result.py    # AnalysisResult ORM model
â”‚   â”‚
â”‚   â””â”€â”€ temp/                     # Temporary file storage for uploads
â”‚
â”œâ”€â”€ frontend/                     # Frontend static files
â”‚   â”œâ”€â”€ index.html                # Main UI
â”‚   â””â”€â”€ script.js                 # Client-side logic
â”‚
â”œâ”€â”€ test/                         # Test files
â”‚   â”œâ”€â”€ test_db.py                # Database tests
â”‚   â””â”€â”€ test_analysis_route.py    # API endpoint tests
â”‚
â”œâ”€â”€ .env.example                  # Environment variable template
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

---

## âš™ï¸ Setup Instructions

Follow these steps to get the application running locally:

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Mamasmess333/Fantastic_Four-.git
cd Fantastic_Four-
```

### 2ï¸âƒ£ Set Up a Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

**Dependencies include:**
- `fastapi` - Web framework
- `uvicorn` - ASGI server
- `boto3` - AWS SDK
- `python-dotenv` - Environment variable management
- `sqlalchemy` - ORM for database
- `psycopg2-binary` - PostgreSQL adapter

### 4ï¸âƒ£ Create Your .env File

Copy the example file and fill in your credentials:

```bash
cp .env.example .env
```

Open `.env` and add your actual values:

```env
# AWS Credentials
AWS_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY=YOUR_AWS_SECRET_ACCESS_KEY
AWS_REGION=us-east-2
S3_BUCKET_NAME=your-s3-bucket-name

# Database Configuration
endpoint=your-database-endpoint.rds.amazonaws.com
db_host=your-database-endpoint.rds.amazonaws.com
db_port=5432
db_name=your_database_name
db_user=your_database_user
db_pass=your_database_password

# Database URL (use your actual values from above)
DATABASE_URL=postgresql+psycopg2://db_user:db_pass@db_host:db_port/db_name
```

### 5ï¸âƒ£ Initialize the Database

```bash
cd backend
python init_db.py
```

This creates the necessary tables in your PostgreSQL database.

### 6ï¸âƒ£ Run the Server

```bash
cd backend
uvicorn app:app --reload
```

The application will start running at:
- **Backend API**: http://127.0.0.1:8000
- **Frontend UI**: http://127.0.0.1:8000
- **API Docs**: http://127.0.0.1:8000/docs

---

## ğŸ§ª API Endpoints

Once the server is running, you can test the API at http://127.0.0.1:8000/docs

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Serves the frontend UI |
| `/upload` | POST | Uploads an image to S3, analyzes it with Rekognition, and saves results to DB |
| `/analyze` | POST | Analyzes an existing image by URL or path |
| `/static/*` | GET | Serves static frontend files |

### Example `/upload` Request

```bash
curl -X POST "http://127.0.0.1:8000/upload" \
  -F "file=@/path/to/image.jpg"
```

**Response:**
```json
{
  "status": "success",
  "labels": ["Pizza", "Food", "Dish", "Cheese"]
}
```

---

## ğŸ§° Environment Variables

| Variable | Description |
|----------|-------------|
| `AWS_ACCESS_KEY_ID` | Your AWS access key |
| `AWS_SECRET_ACCESS_KEY` | Your AWS secret key |
| `AWS_REGION` | AWS region for services (e.g., `us-east-2`) |
| `S3_BUCKET_NAME` | Name of your S3 bucket for image storage |
| `db_host` | PostgreSQL database host (RDS endpoint) |
| `db_port` | Database port (default: `5432`) |
| `db_name` | Database name |
| `db_user` | Database username |
| `db_pass` | Database password |
| `DATABASE_URL` | Full PostgreSQL connection string |

---

## ğŸ—„ï¸ Database Schema

### `analysis_results` Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | Integer | Primary key, auto-increment |
| `status` | String | Analysis status (e.g., "success") |
| `labels` | JSON | Array of detected labels |
| `image_url` | String | S3 URL of uploaded image |
| `created_at` | DateTime | Timestamp of record creation |

---

## ğŸ§‘â€ğŸ’» Developer Notes

- **Never push your real `.env` file** â€” it's ignored by Git for security
- To update dependencies after adding new packages:
  ```bash
  pip freeze > requirements.txt
  ```
- To deactivate your environment:
  ```bash
  deactivate
  ```
- The `temp/` folder is created automatically for temporary file storage during uploads
- S3 files are saved with unique UUIDs to prevent naming conflicts

---

## ğŸ§ª Testing

Run tests using pytest:

```bash
pytest test/
```

---

## ğŸ“¦ Deployment

This project can be deployed on:
- **AWS EC2** (with RDS for database)
- **Render**
- **Railway**
- **Heroku**
- Or any VPS that supports Python 3.10+ and FastAPI

**Note**: Make sure to set all environment variables in your deployment platform's configuration.

---

## ğŸ Summary

âœ… AWS Rekognition + S3 integration for image analysis
âœ… PostgreSQL database with SQLAlchemy ORM
âœ… RESTful FastAPI backend with organized architecture
âœ… Static frontend hosting
âœ… Secure environment-based configuration
âœ… Easy setup for all team members

---

## ğŸ‘¥ Team Members & Contributions

### Jehun Kim's Contributions (branch: jkim)

**Backend Architecture & AWS Integration**

- **Project Restructuring**: Created `backend/` folder and reorganized project structure by moving `services/`, `routes/`, and `app.py` into organized directories
- **Database Integration**: Set up and configured AWS RDS PostgreSQL connection and implemented database persistence - analyzed data is now successfully saved to the database
- **Testing & Quality**: Built and refactored `test_db.py` for improved test coverage and maintainability
- **S3 Upload Fix**: Fixed critical bug where empty image files were being saved to S3 - now actual image files are properly uploaded with full content
- **Code Quality**: Fixed typos in `s3_service.py` and refactored upload logic for better reliability
- **Environment Configuration**: Updated `.env.example` to include comprehensive database configuration and DATABASE_URL examples
- **AWS Infrastructure**: Enhanced and customized the existing AWS setupâ€”including S3, RDS PostgreSQL, and EC2â€”by modifying configurations and integrations to ensure seamless functionality with the projectâ€™s backend services

---

**Developed by the Fantastic Four Team** ğŸ’»
